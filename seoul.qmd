---
title: "Seasonality in Seoul: Multilinear Modeling with Kth Differences and Fixed Effects"
author:
  - "Ketherine Wang"
  - "Sam Lee"
format: pdf
editor: visual
fontsize: 9pt
---

```{=html}
<style type="text/css">
h1.title {
font-size: 40px;
text-align: center;
}
h4.author {
font-size: 40px;
text-align: center;
}
</style>
```
\newpage

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(GGally)
library(corrplot)
library(patchwork)
library(car)
library(ggfortify)
library(alr4)
library(glmnet)
library(broom)
library(robustbase)
library(gridExtra)
library(httr)
library(jsonlite)
library(tibble)


set.seed(12022023)

seoul <- read.csv("SeoulBikeData.csv", header=F, skip=1) %>% setNames(
  c("Date", "RentedBikeCount", "Hour", "Temperature", "Humidity", "WindSpeed",
    "Visibility", "DewPointTemp", "SolarRadiation", "Rainfall", "Snowfall",
    "Seasons", "Holiday", "FunctioningDay")
) %>% as_tibble() %>%
  mutate(
    Date = dmy(Date),
    Time = ymd_h(paste(Date, Hour)),
    IsAutumn = 1*(Seasons == "Autumn"),
    IsSummer = 1*(Seasons == "Summer"),
    IsWinter = 1*(Seasons == "Winter"),
    IsSpring = 1*(Seasons == "Spring"),
    IsHoliday = 1*(Holiday == "Holiday"),
    Hour09 = 1*(Hour %in% 0:9),
    Hour1018 = 1*(Hour %in% 10:18),
    Hour1924 = 1*(Hour %in% 19:24)
  ) %>% arrange(Time)
```

# Abstract

In this analysis we explore which factors primarily drive short-run fluctuations as they depend on Seasonality. We examine the changes in temperature as well as the demand for bike rentals in Seoul, South Korea. We conducted multiple linear regression using weather predictors from 2018 hourly data. We found that the the marginal effect of solar radiation on temperature change was most significant from 8:00 PM to 9:00 PM. Additionally, the marginal effects of solar radiation had a negative affect on bike demand; however, the interaction effects during peak demand times (rush hour times, for example), proved to be significantly positive.

# 1 Problem and Motivation

We are examining data from Seoul, Korea, to understand how weather and time influence bike sharing and temperature changes in the city. This data, which includes details about whether conditions and bike rentals over 8,456 days, is crucial for urban planning and environmental studies. Our goal is to identify which factors most affect bike usage and temperature fluctuations. This information is important because it helps city planners make better decisions about transportation and infrastructure, especially as cities around the world are focusing more on sustainable living and environment challenges. By understanding these patterns, we can help make cities like Seoul more efficient and responsive to both their climate and the needs of their residents.

## 1.1 Data Description

In this analysis we used data from UC Irvine's Machine Learning's Repository. We accessed [Seoul Bike Sharing Data](https://archive.ics.uci.edu/dataset/560/seoul+bike+sharing+demand), which contains 8,760 rows of hourly data pertaining to the corresponding amount of rented bikes (bike demand) in Seoul, Korea. 8,465 rows are considered "functioning days," where bikes are able to be rented. In order to consider our problem of interest, we will only consider these 8,465 rows to model the bike demand in Seoul. This data set also contains corresponding data for the respective temperature (celcius), humidity (%), wind speed (m/s), visibility (10m), dew point temperature (celcius), solar radiation (MJ/$m^2$), rainfall precipitation (mm), snowfall precipitation (cm), seasons (Winter, Spring, Summer, Autumn), and an indicator determining whether the corresponding day is a holiday.

We will use these variables along with a subset of interaction terms which will be determined by elastic net regression to include in our models.

## 1.2 Questions of Interest

1.  Can we use factors in weather and time to determine the best predictors of short-run for fluctuations in temperature for the climate in Seoul, Korea? 

2.  Can we determine which weather and time factors affect the bike sharing demand the most in Seoul, Korea?

If there are significant predictive factors, which one has the largest influence?

```{r echo=FALSE}
difference = 5
seasons = unique(seoul$Seasons)
Temp = seoul[c("Time", "Temperature", "Seasons")]

season.base = "IsSpring"
season.dummies = setdiff(c("IsWinter", "IsSpring", "IsSummer", "IsAutumn"), season.base)

time.base = "Hour1924"
time.dummies = setdiff(c("Hour09", "Hour1018"), time.base)

time.bike = c()
for(h in unique(seoul$Hour)){
  factor = str_c("Hour", h)
  seoul[factor] = as.numeric(seoul$Hour == h)
  time.bike = c(time.bike, factor)
}
time.bike.base = "Hour0"
time.bike = setdiff(time.bike, time.bike.base)

time.dummies = time.bike

seoul.factors = c("Temperature", "Humidity", "DewPointTemp",
                  "WindSpeed", "Visibility", "SolarRadiation", "Rainfall",
                  "Snowfall", time.dummies)

seoul.change = c()
seoul.interaction = c()
seoul.base = c(time.base)
humidity.interactions = c()

format_change_table = function(t=seoul, f=seoul.factors){
  for(factor in f){
    change_factor = str_c(factor, "Change")
    seoul.change <<- c(seoul.change, change_factor)
    t[change_factor] = NA_real_
    for(s in seasons){
      seoul.subset = t %>% filter(Seasons == s)
      t[t$Seasons == s, change_factor] = seoul.subset[factor]-lag(seoul.subset[factor], n=difference)
    }
  }
  
  #All 2d Interaction Effects
  continuous_interactions = combn(setdiff(seoul.change, 
                                          c(str_c(time.dummies, "Change"),
                                            str_c(season.dummies, "Change"),
                                            "TemperatureChange")), 2)
  for(i in 1:ncol(continuous_interactions)){
    factor = paste(continuous_interactions[,i], collapse = "X")
    seoul.interaction <<- c(seoul.interaction, factor)
    t[factor] = NA_real_
    for(s in seasons){
      seoul.subset = t %>% filter(Seasons == s)
      t[t$Seasons == s, factor] = seoul.subset[continuous_interactions[1,i]]*
                                          seoul.subset[continuous_interactions[2,i]]
    }
  }
  
  #Time Interaction Effects
  for(factor in setdiff(seoul.change, 
                        c(str_c(time.dummies, "Change"),
                          "TemperatureChange"))){
    for(time in str_c(time.dummies, "Change")){
      factor.interaction = str_c(factor, "X", time)
      seoul.interaction <<- c(seoul.interaction, factor.interaction)
      seoul[factor.interaction] = NA_real_
      for(s in seasons){
        seoul.subset = t %>% filter(Seasons == s)
        t[t$Seasons == s, factor.interaction] = seoul.subset[factor]*
                                                        seoul.subset[time]
      }
    }
  }
  return(t)
}
seoul = format_change_table(seoul)

###### Rented Bike Count Model

a = 1 #1 is excluded for base dummy
time.humidities = str_c("Humidity",setdiff(1:10, a))
for(h in 1:length(time.humidities)){
  h.min = (h-1+a)*10
  h.max = (h+a)*10
  seoul[time.humidities[h]] = 1*(seoul$Humidity >= h.min &
                                 seoul$Humidity < h.max)
}

bike.deltas = c()
calculate_deltas = function(v=seoul$RentedBikeCount){
  bike.deltas <<- c()

  deltas.choice = 1:9
  for(delta in deltas.choice){
    factor = str_c("RentedBikeCount_Lag", delta)
    seoul[factor] = lag(v, n=delta)
    bike.deltas <<- c(bike.deltas, factor)
  }
  
  seoul <<- seoul
}
calculate_deltas()

bike.dummies = c("IsHoliday")
seoul.bike.factors = c("RentedBikeCount", "Humidity", "Temperature",
                       "WindSpeed", "Visibility", "DewPointTemp",
                       "SolarRadiation",
                       "Rainfall", "Snowfall", bike.dummies, time.bike,
                       season.dummies, bike.deltas)


seoul.bike.transformed = c(time.humidities, "ExtremeWind", "WindSpeedTransformed",
                           "VisibilityTransformed")

# seoul.bike.factors = c(seoul.bike.factors, seoul.bike.transformed)

seoul.bike.interaction = c()
seoul.bike.base = c(time.bike.base)

create_interaction_terms = function(t, f=seoul.bike.factors){
  
  seoul.bike.interaction <<- c()
  
  continuous_interactions_bike = combn(setdiff(f, 
                                        c(time.bike, season.dummies,
                                          time.humidities,
                                          "RentedBikeCount")), 2)
  for(i in 1:ncol(continuous_interactions_bike)){
    factor = paste(continuous_interactions_bike[,i], collapse = "X")
    seoul.bike.interaction <<- c(seoul.bike.interaction, factor)
    t[factor] = t[continuous_interactions_bike[1,i]]*
                    t[continuous_interactions_bike[2,i]]
  }
  
  for(factor in setdiff(f,
                          c(time.bike, season.dummies, "RentedBikeCount"))){
    for(time in time.bike){
      factor.interaction = str_c(factor, "X", time)
      seoul.bike.interaction <<- c(seoul.bike.interaction, factor.interaction)
      t[factor.interaction] = t[factor]*t[time]
    }
  }
  
  #Seasonal Interactions
  for(factor in setdiff(f,
                          c(season.dummies, "RentedBikeCount"))){
    for(s in season.dummies){
      factor.interaction = str_c(factor, "X", s)
      seoul.bike.interaction <<- c(seoul.bike.interaction, factor.interaction)
      t[factor.interaction] = t[factor]*t[s]
    }
  }
  #Humidity and Other Weather Effects
  for(factor in setdiff(f,
                          c(time.bike, season.dummies,
                                            time.humidities,
                                            "RentedBikeCount"))){
    for(humidity in time.humidities){
      factor.interaction = str_c(factor, "X", humidity)
      seoul.bike.interaction <<- c(seoul.bike.interaction, factor.interaction)
      humidity.interactions <<- c(humidity.interactions, factor.interaction)
      t[factor.interaction] = t[factor]*t[humidity]
    }
  } 

  
 return(t)
}
seoul = create_interaction_terms(seoul)

seoul[complete.cases(seoul[seoul.change]), ] -> seoul.temp
```

## 1.3 Regression Methods & Model Determination/Selection Procedures

We decided to run a first differences model to model the fluctuations in short-run temperature. where $\Delta\text{Temperature}_t = \text{Temperature}_t - \text{Temperature}_{t-k}$. We found that the optimal choice of $k$ was $5$ (see [A.0](#a0) for optimal selection process on $k$).

Thus, we wish to estimate,

(1) $\Delta\text{Temperature}_{st} = \beta_1\Delta\text{Humidity}_{st} + \beta_2\Delta\text{DewPointTemp}_{st} + \beta_3\Delta\text{WindSpeed}_{st} + \beta_4\Delta\text{SolarRadiation}_{st} + \beta_5\Delta\text{Rainfall}_{st} + \beta_6\Delta\text{Snowfall}_{st} + \Delta\beta_7I(\text{Hour}_{t} = 1) + ... + \Delta\beta_{29}I(\text{Hour}_{t} = 23) + \Delta\eta_{st}$

Where $\Delta\text{Temperature}_{st} = \text{Temperature}_{st} - \text{Temperature}_{t-5}$

```{r message=F, echo=F, fig.size=16}
corrplot(cor(seoul.temp[seoul.change %>% 
         setdiff(str_c(time.dummies, "Change"))]), 
         type="upper")
```

With our basic multilinear model (1) the correlation matrix indicates that there may be some potential multicolinearity between $\text{DewPointTempChange}_{st}$ and $\text{HumidityChange}_{st}$. For the most part, the indicators look good with changes in $\text{SolarRadiation}_{st}$ potentially affecting flucutations in temperature the most.

Change in Temperature Across Hours of the Day by Season

```{r echo=F, fig.width=12}
seoul.temp %>% ggplot()+
  geom_point(aes(x=Hour, y=TemperatureChange), size=0.25)+
  facet_grid(~Seasons)+
  ylab(expression(Delta~Temperature))
```

According to our model, changes in temperature not only depend on temperature but also on season. While there are some general linear trends across some ranges of hours, the non-linearity of the hours in general with respect to temperature change led us to include indicators for each hour as specified in Model (1) using Hour 0 (12:00 a.m.) as our base year.

```{r echo=F}
show_leverage = function(model){
  cd_cont_pos <- function(leverage, level, model) {
    sqrt(level * length(coef(model)) * (1 - leverage) / leverage)
  }
  cd_cont_neg <- function(leverage, level, model) {
    -cd_cont_pos(leverage, level, model)
  }
  
  cd_threshold <- 0.5
  cd_threshold2 <- 4 / (nrow(seoul) - 2)
  x_max_val <- 0.35
  
  autoplot(model, which = 5, nrow = 1, ncol = 1) +
    theme(aspect.ratio = 1) +
    stat_function(fun = cd_cont_pos,
                  args = list(level = cd_threshold, model = model),
                  xlim = c(0, x_max_val), lty = 2, colour = "#FFACEE") +
    stat_function(fun = cd_cont_neg,
                  args = list(level = cd_threshold, model = model),
                  xlim = c(0, x_max_val), lty = 2, colour = "#FFACEE") +
    stat_function(fun = cd_cont_pos,
                  args = list(level = cd_threshold2, model = model),
                  xlim = c(0, x_max_val), lty = 2, colour = "#AFDFFF") +
    stat_function(fun = cd_cont_neg,
                  args = list(level = cd_threshold2, model = model),
                  xlim = c(0, x_max_val), lty = 2, colour = "#AFDFFF")
}
```

<!-- According to the model diagnostics [A.1.0](#a10), the linearity assumption seems to met (see [A.1](#a11) for added variable plots). Additionally, though there were some points moving the model away from homoskedasticity the $\sqrt{|\text{Standardized residuals}|)}$ vs. Fitted values Plot shows that homoskedasticity is roughly met. However, the normality assumption was blatantly violated so we considered adding in interaction terms. -->

We used elastic net regression to select interaction terms to see if the influential points (and thus, Normality) could be remedied. We used elastic net regression over lasso regression due to the potential colinearity between $\text{HumidityChange}_{st}$ and other weather effects. (See [A.2.0](#a20) for model output)
---
Similar to our model for temperature, we have unobserved seasonal effects in $\epsilon$. Instead of using a $k$th-difference approach, we will use a fixed effects models to include the seasonal effects for $s-1$ (3) seasons to obtain unbiased estimates. We will use Spring as our base season. However, exploratory data analysis has shown that current bike demand is strongly dependent on the bike demand from previous hours. Hence, in order to include seasonal dummy variables, we also need to include a set of lagged effects ($\delta_{p}$) conditional on Season on $\text{RentedBikeCount}_{st} \quad \forall s \in \text{Seasons}, s\neq\text{Spring}$ to adjust for the time dependency. (See [A.7](#a7) to see how we chose our set of lagged effects).

```{r echo=F, fig.width=12}
threshold = 0.25
seoul %>% mutate(IsPrecip=(Rainfall+Snowfall) > threshold) %>% ggplot()+
  geom_point(aes(x=Hour, y=RentedBikeCount, color=IsPrecip), size=0.25)+
  facet_grid(~Seasons)+
  ylab("Rented Bike Demand")+
  guides(color=guide_legend(title="Significant Precipitation"))
```
Preliminary EDA shows that precipitation (rain and snow) will have a significant negative effect on rented bike demand.

Hence, we will first estimate the hourly demand for rented bikes in Seoul with the following model (see [A.8.0](#a80) for full model description),
 
(3) $\text{RentedBikeCount}_{st} = \beta_0 + \beta_1\text{Humidity}_{st} + \beta_{2}\text{Temperature}_{st} + ... + \beta_{33}I(\text{Season}_s = \text{Winter}) + \beta_{34}I(\text{Season}_s = \text{Summer}) + \beta_{35}I(\text{Season}_s = \text{Autumn}) + \delta_1\text{RentedBikeCount}_{st-1} + \delta_{23}\text{RentedBikeCount}_{st-23} + \sum_{p=1}^{9}\delta_p + \eta_{st}$

$\eta_{st} \overset{iid}{\sim} N(0, \sigma^2)$

Diagnostics for fitting this model to this data indicate that linearity is met [A.8](#a8). Additionally, due to the large sample size, the leverage plot also indicates that there were not any influential points. However, since homoskedasticity was blatantly violated, especially for fitted values < 1000, we modified the model by including interaction terms.

We ran an elastic net regression model to control for colinearity. (See model [A.9](#a9) for model output and diagnostics). Since $\text{RentedBikeCount}_{st}$ is likely poisson-distributed, we considered log-transforming the response, but diagnostics show that model assumptions did not improve [A.10.0](#a100).

However, we noticed non-linear trends in $\text{Humidity}_{st}$ against $\text{RentedBikeCount}_{st}$ and introduced categorical transformations [A.10.1](#a101). Using an inverse response plot, we also found that we could optimally transform $\text{Visibility}_{st}$ using a $log$ transformation [A.10.2](#a102). Lastly, we transformed $\text{WindSpeed}_{st}$ since we noticed that extreme values were causing some non-linearity between the response. Hence, we introduced a categorical variable called $\text{ExtremeWind}_{st}$ to capture this effect [A.10.3](#a103).

```{r echo=F}
seoul %>% group_by(Seasons) %>%
  mutate(
    ExtremeWind = 1*(WindSpeed >= quantile(WindSpeed, 0.9)),
    WindSpeed = ifelse(
      WindSpeed < quantile(WindSpeed, 0.9), log(WindSpeed+1), 0
    )
  ) %>% ungroup() -> seoul.bike

seoul.bike.factors.alt = c(setdiff(seoul.bike.factors, "Humidity"), time.humidities, "ExtremeWind")
seoul.bike$Visibility = log(seoul$Visibility+1)
seoul.bike <- create_interaction_terms(seoul.bike, seoul.bike.factors.alt)

singularities = c("SolarRadiationXHour1", "SolarRadiationXHour2", "SolarRadiationXHour3",
                  "SnowfallXIsFunctioningDay", "SolarRadiationXHour4",
                  "SolarRadiationXHour5", "SolarRadiationXHour20", "SolarRadiationXHour21",
                  "SolarRadiationXHour22", "SolarRadiationXHour23", "SnowfallXIsSummer",
                  "SnowfallXIsAutumn")
model.bike.factors = setdiff(c(seoul.bike.factors.alt, seoul.bike.interaction), 
                             c(seoul.bike.base, "RentedBikeCount", singularities))

seoul.bike.x = as.matrix(seoul.bike[(length(bike.deltas)+1):nrow(seoul.bike),model.bike.factors])
seoul.bike.y = as.matrix(seoul.bike[(length(bike.deltas)+1):nrow(seoul.bike),"RentedBikeCount"])

elastic_cv <- cv.glmnet(x = seoul.bike.x,
                      y = seoul.bike.y, 
                      type.measure = "mse", 
                      alpha = 1)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.bike.factors)-1)]


elastic.bike.factors = c(model.bike.factors[which(d != 0)])

#Add lower level terms
elastic.bike.factors = c(elastic.bike.factors, 
                         setdiff(seoul.bike.factors.alt,
                        c("RentedBikeCount", elastic.bike.factors)))

seoul.bike.elastic = lm(RentedBikeCount ~ .,
                                       seoul.bike[c("RentedBikeCount",
                                       elastic.bike.factors)])

autoplot(seoul.bike.elastic)
```

## 4. Analyses, Results and Interpretation:

Thus, using our elastic regression results, we will modify Model (1) to include the following interaction terms. We made sure to include the lower-order regression coefficients for the coefficients that elastic net regression left out when elastic net included interaction terms involving a lower-order term. We are interested in estimating the most assailant factors ([A.5](#a5)). See [A.6](#a6) for the full model.

(2) $\Delta\text{Temperature}_{st} = ... + \beta_5\Delta\text{SolarRadiation}_{st} + ... +  \beta_{32}\Delta\text{Humidity}_{st}\text{SolarRadiation}_{st} + ... + \beta_{39}\Delta\text{SolarRadiation}_{st}\text{Rainfall}_{st} + ... + \sum_{n=1}^{23}{\beta_{131+n}\Delta\text{SolarRadiation}_{st}\Delta I(\text{Hour}_t=n)} + ... + \Delta\eta_{st}$

$\Delta\eta_{st} \overset{iid}{\sim} N(0, \sigma^2)$

Using an elastic net regression method to determine once again the appropriate coefficients to include [A.11](#a11), we have determined our final model for measuring the demand for rented bikes in Seoul,

(4) $\text{RentedBikeCount}_{st} = \beta_0 +...+ \beta_{11}\text{Rainfall}_{st} +...+\beta_{17}\text{SolarRadiation}_{st}+\beta_{19}I(\text{Season}_s = \text{Winter}) + \beta_{20}I(\text{Season}_s = \text{Summer}) + \beta_{21}I(\text{Season}_s = \text{Autumn}) + ...+\beta_{240}\text{SolarRadiation}_{st}I(\text{Hour}_t=8)+\beta_{241}\text{SolarRadiation}_{st}I(\text{Hour}_t=19)+\beta_{242}\text{Rainfall}_{st}I(\text{Hour}_t=9)+\beta_{243}\text{Rainfall}_{st}I(\text{Hour}_t=13)+\beta_{244}\text{Rainfall}_{st}I(\text{Hour}_t=17)+\beta_{245}\text{Rainfall}_{st}I(\text{Hour}_t=19)+\beta_{246}\text{Rainfall}_{st}I(\text{Hour}_t=20)+... + \eta_{st}$

$\eta_{st} \overset{iid}{\sim} N(0, \sigma^2)$

(The full model is referenced in [A.13](#a13), only assailant terms are included for simplicity.

#### Diagonostic Checks

For both models, model (2) (Temperature Change) and model (4) (Bike Sharing Demand),

Based on the Residuals vs. Fitted Values plot below, the linearity assumption appears to be met. There is a straight blue curve across most of the fitted values with majority of the residuals randomly distributed around the horizontal line at y = 0.

From the Normal Q-Q plot below, the plot shows that the points deviate from the reference line, especially in the tails. This suggests that the data may have heavier tails than a normal distribution, indicating the presence of outliers or a non-normal distribution of residuals.

However, even with selected interaction terms included, Normality did not drastically improve (see [A.2.1](#a21) for QQ-Plot).

We considered transforming the model (1) ([A.3](#a3)) to better meet normality and somewhat homoskedasticity. However, due to the nature of our $X$ variable matrix, since each independent variable is a change in a variable, we thus had to shift the entire vector of that corresponding variable in order to derive optimal transformations. Hence, interpreting any transformations we would make would prove difficult and impractical.

However, with large sample size ($n=8740$), normality could be appealed to. The residuals do appear to be normal, though extreme values cause deviations from normality in the tails as seen in the Normal Q-Q plot. We considered alternatives to meeting the assumptions such as linear robust regression to reduce the weights of outliers. One alternative is further discussed in [A.4](#a4), where we considered estimating a model for each season.

Histogram of Residuals from Elastic Net Regression

```{r echo=F, fig.width=18, message=F}
model.factors = setdiff(c(seoul.change, seoul.interaction), 
                        c(seoul.base, "TemperatureChange"))

seoul.x = as.matrix(seoul.temp[model.factors])
seoul.y = as.matrix(seoul.temp["TemperatureChange"])

elastic_cv <- cv.glmnet(x = seoul.x,
                      y = seoul.y, 
                      type.measure = "mse", 
                      alpha = 0.5)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.factors)-1)]
elastic.factors = c(model.factors[which(d != 0)])
elastic.factors = c(elastic.factors, setdiff(c(str_c(time.bike, "Change"), "RainfallChange"), elastic.factors))
seoul.elastic = lm(TemperatureChange ~ 0 + .,
                                       seoul.temp[c("TemperatureChange",
                                       elastic.factors)])

elastic.hist = ggplot()+
  geom_histogram(aes(x=seoul.elastic$residuals), fill="steelblue")+
  xlab(expression("Reisduals of "~Delta~Temp~" Model"))+
  ylab("")+
  theme_minimal()

elastic.hist.bike = ggplot()+
  geom_histogram(aes(x=seoul.elastic$residuals), fill="coral")+
  xlab("Reisduals of Bike Demand Model")+
  ylab("")+
  theme_minimal()


grid.arrange(elastic.hist, elastic.hist.bike, ncol=2)
```
Since the histogram of the residuals above appears to be normal, aside from the extreme values in the tails in the Normal Q-Q plot, it is important to note that with large datasets, such as ours, the central limit theorem suggests that the sampling distribution of the regression coefficients will tend to be normally distributed, even if the residuals are not. This implies that the violation of the normality assumption may not substantially affect the validity of our inferential statistics, like confidence intervals and hypothesis tests..

Additionally, the homoscedasticity assumption appears to be met. In the Scale-Location plot ([A.2.1](#a21)), there is a straight and horizontal blue curve for most of the fitted values. The points are evenly spread out above and below the curve. Even though there is a slight curvature in the blue line shown in the plot due to effects of some outliers, overall, I think that the homoscedasticity assumption is met.

Lastly, from the Residuals vs. Leverage plot ([A.2.1](#a21)), none of the standardized residuals falls outside the 0.5 Cook's distance thresholds. Therefore, we can conclude that there is no unduly influential points.

```{r}
autoplot(seoul.elastic)
show_leverage(seoul.elastic)

autoplot(seoul.bike.elastic)
show_leverage(seoul.bike.elastic)
```

### Inferential Statistics

<!-- #### Reduced Model Test - Elastic Net Model with Solar Radiation Factors vs. without Solar Radiation Factors -->

<!-- ```{r} -->
<!-- sr.factors = model.factors[model.factors %>% str_detect("SolarRadiation")] -->

<!-- seoul.elastic.reduced.factors = setdiff(model.factors, sr.factors) -->

<!-- seoul.elastic.reduced = lm(TemperatureChange ~ 0 + .,  -->
<!--                            seoul.temp[c(seoul.elastic.reduced.factors, "TemperatureChange")]) -->

<!-- # anova(seoul.elastic.reduced, seoul.elastic) -->
<!-- ``` -->

#### 95% Confidence Interval of $\beta_5$ for Solar Radiation Change

```{r}
conf_ints <- confint(seoul.elastic, level = 0.95)
conf_ints['SolarRadiationChange', ]
```

Holding all else constant, we are 95% confident that the true estimated average temperature change in Seoul will be between 0.8726519 and 1.0023804 Celsius when additional one MJ/$m^2$ increase in solar radiation change. The 95% confidence interval of $\beta_5$ for solar radiation change does not include zero. It suggests that the effect of solar radiation change on the average temperature change is statistically significant. In other words, there is a significant association between these variables.

#### 95% Confidence Interval of $\beta_241$ for Solar Radiation at Hour 19

```{r}
conf_ints <- confint(seoul.bike.elastic, level = 0.95)

solar_radiation_ci <- conf_ints['SolarRadiationXHour19', ]
print(solar_radiation_ci)
```

Holding all else constant, we are 95% confident that the true estimated bike sharing demand in Seoul will be between 0.8726519 and 1.0023804 Celsius when additional one MJ/$m^2$ increase in solar radiation change. The 95% confidence interval of $\beta_5$ for solar radiation change does not include zero. It suggests that the effect of solar radiation change on the average temperature change is statistically significant. In other words, there is a significant association between these variables.

#### 95% Prediction Interval (see [A.15](#a15) for API code/data retrieval)

```{r warning=F, echo=F, fig.width=18}
api_url <- "https://api.open-meteo.com/v1/forecast?latitude=37.566&longitude=126.9784&hourly=temperature_2m,relative_humidity_2m,dew_point_2m,rain,snowfall,visibility,wind_speed_10m,diffuse_radiation&wind_speed_unit=ms&past_days=7"

response <- GET(api_url)
fetch_time = ymd_h(paste(Sys.Date(), hour(now())))
content <- content(response, "text", encoding = "UTF-8")

data <- fromJSON(content)

hourly_data <- data$hourly

forecast <- as_tibble(hourly_data) %>% mutate(
  time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M"),
  diffuse_radiation = diffuse_radiation/100,
  visibility = visibility/100,
  Hour = time %>% hour(),
  f = time >= as.POSIXct(fetch_time, format = "%Y-%m-%dT%H:%M")
) %>% setNames(c("Time", "Temperature", "Humidity", "DewPointTemp", "Rainfall", "Snowfall",
               "Visibility", "WindSpeed", "SolarRadiation", "Hour", "Forecast"))

forecast$Seasons = "Winter"

time.forecast = c()
for(h in unique(forecast$Hour)){
  factor = str_c("Hour", h)
  forecast[factor] = as.numeric(forecast$Hour == h)
  time.forecast = c(time.forecast, factor)
}
time.forecast.base = "Hour0"
time.forecast = setdiff(time.forecast, time.forecast.base)

forecast.factors = c("Temperature", "Humidity", "DewPointTemp",
                  "WindSpeed", "Visibility", "SolarRadiation", "Rainfall",
                  "Snowfall", time.forecast)

forecast = format_change_table(forecast)

forecast$PredictedChange = predict(seoul.elastic, forecast)
forecast$PredictedTemperature = forecast$PredictedChange+
  lag(forecast$Temperature, n=difference)

forecast[complete.cases(forecast[forecast.factors]),] -> forecast

pred_ints <- predict(seoul.elastic,
        newdata = forecast,
        interval = "prediction",
        level = 0.95)

forecast$LowerBoundTemperatureChange = pred_ints[, "lwr"]
forecast$UpperBoundTemperatureChange = pred_ints[, "upr"]

forecast$LowerBoundTemperature = forecast$LowerBoundTemperatureChange +
  lag(forecast$Temperature, n=difference)
forecast$UpperBoundTemperature = forecast$UpperBoundTemperatureChange +
  lag(forecast$Temperature, n=difference)

p.change = forecast %>% ggplot(aes(x=Time, y=TemperatureChange, color=Forecast))+
  geom_line() +
  geom_ribbon(aes(ymin=LowerBoundTemperatureChange, ymax=UpperBoundTemperatureChange), 
              color=NA, fill="#14DD32", alpha=0.2) +
  geom_line(aes(y=PredictedChange), color="#14DD32", alpha=0.5)+
  ylab(expression(Delta~Temperature))+
  labs(
    title="Current Weekly Forecast of Change in Temperature in Seoul",
    subtitle = "Overlaid by Prediction"
  )+
  guides(color="none")+
  theme_minimal()

p.temp = forecast %>% ggplot(aes(x=Time, y=Temperature, color=Forecast))+
  geom_line() +
  geom_ribbon(aes(ymin=LowerBoundTemperature, ymax=UpperBoundTemperature),
              color=NA, fill="#14DD32", alpha=0.2) +
  geom_line(aes(y=PredictedTemperature), color="#14DD32", alpha=0.5)+
  ylab("Temperature")+
  labs(
    title="Current Weekly Forecast of Temperature in Seoul",
    subtitle = "Overlaid by Prediction"
  )+
  theme_minimal()

grid.arrange(p.change, p.temp, ncol=2)

predict(seoul.elastic,
        newdata = tail(forecast, 5)[1,],
        interval = "prediction",
        level = 0.95)
```

```{r warning=F, echo=F}
seoul.bike$PredictedBikeCount = predict(seoul.bike.elastic, seoul.bike)
seoul.bike %>% 
  ggplot()+
  geom_line(aes(x=Time, y=RentedBikeCount, color="Actual"), alpha=1)+
  geom_line(aes(x=Time, y=PredictedBikeCount,
                color="Predicted"), alpha=0.3)+
  facet_grid(~factor(seoul$Seasons, 
                     levels=c("Winter", "Spring", "Summer", "Autumn")), 
             scales="free_x")+
  labs(title="Predicted Bike Demand in Seoul Over Time",
       color=NULL)+
  xlab("Time")+
  ylab("Rented Bike Count")+
  theme(axis.text.x = element_text(angle = 45, hjust = 0, vjust = 0))
```
## 5. Conclusions

For temperature changes, our multilinear model suggests a significant correlation with solar radiation, particularly during evening hours. The confidence interval for the effect of solar radiation on temperature change does not include zero, indicating a substantial impact. Interestingly, while solar radiation generally increased temperature, its interaction with other factors like rainfall showed a negative effect on bike demand, except during peak hours where the effect was positive. This nuanced relationship highlights the complexity of weather's impact on urban activities.

Regarding bike-sharing demand, our analysis revealed strong seasonality and time dependencies. Notably, humidity and solar radiation played significant roles, with solar radiation's impact on demand varying by hour and season. The confidence interval for the interaction between solar radiation and bike-sharing demand at 7 PM underlines this point, demonstrating a significant effect during this time.

<!-- The diagnostic checks for our models confirmed the assumptions of linearity and homoskedasticity were mostly met, with the exception of normality due to extreme values. The large sample size allowed us to appeal to the central limit theorem for the normality of our regression coefficients, despite the residuals' deviation from normality. -->

Given that we controlled for time-series independence using regression techniques such as kth-differences and fixed effects, our findings are believed to be reliable within the context of Seoul's climate and urban dynamics. While the results are specific to Seoul, they may also provide valuable insights for similar metropolitan areas with comparable climates and bike-sharing systems. However, caution should be exercised when generalizing beyond these conditions.

In conclusion, the study's results offers a deeper understanding of the intricate interplay between weather conditions, time factors, and urban mobility in Seoul. This information is crucial for city planners and policymakers aiming to promote sustainable transportation and urban living. Further research could explore these relationships in different contexts or extend the analysis to other forms of urban mobility.

## 6. Contributions

## APPENDIX

#### A.0 {#a0}

Selection Process for Optimal Choice of $k$

Temperature is highly dependent on the temperature from the hour before ($t-1$): $\frac{\hat{\text{Cov}}(\text{Temperature}_t,\text{Temperature}_{t-1})}{\hat{Var}(\text{Temperature}_t)}$ = `r round(lm(seoul$Temperature ~ lag(seoul$Temperature, n=1))$coef[2], 4)` (which is significant).

Since we have hourly data, running a first difference regression model will, though eliminate the dependency on the value from $t-1$, may also leave the dependency from $t-2,...t-(k-1)$ left over. If $\Delta\text{Temperature}_t = \text{Temperature}_t - \text{Temperature}_{t-k}$, We will find the $k$ (the $k$th difference) such that there is no longer a direct dependency between $\Delta\text{Temperature}_t$ and $\Delta\text{Temperature}_{t-k}$. In other words, We want to find the smallest possible $k$ such that $cov(\Delta\text{Temperature}_t, \Delta\text{Temperature}_{t-k}) = 0$.

We want $k$ as small as possible because we want as much data for our model: Our belief is that short-run fluctuations in temperature can be determined by other short-run changes in other factors. Hence, the smaller $k$ is, the better predictions we can make about the hour $t$. If we wanted to parse out a long-run effect, we would aggregate on a time period and regress over that interval. However, for the purposes of our research question, we need to be informed the most about what is happening in the short-run.

Running a $k$th difference regression model where $\Delta\text{Temperature}_t = \text{Temperature}_t - \text{Temperature}_{t-k}$ we can find a sufficient $k$ by regressing $\Delta\text{Temperature}_{t-1}$ on $\Delta\text{Temperature}_{t-k^*}$, where $k*$ is the proposed value of $k$. We will choose $k=k^*$ when the regression coefficient becomes non-significant. This (non-coincidentally) happens as the regression coefficient approaches 0, or $\Delta\text{Temperature}_t$ becomes less and less dependent of the $\Delta\text{Temperature}$ from $k^*$ hours ago.

The optimal choice of $k$ will lead us to run a $k$th difference regression model where $\Delta\text{Temperature}_t = \text{Temperature}_t - \text{Temperature}_{t-k}$.

Optimal choice of $k$:

```{r}
ks = c()
alpha = 0.1
for(k in 1:100){
  k.change = seoul$Temperature - lag(seoul$Temperature, n = 1)
  k.lm = lm(k.change ~ lag(k.change, n = k))
  k.p = summary(k.lm)$coefficients[, "Pr(>|t|)"][2]
  if(k.p > alpha){
    ks = c(ks, k)
  }
}

ks
```

Hence, we chose $k$ = `r first(ks)`

We also hypothesized that since there are seasonal effects that are unobservable in our data set, the error term, $\epsilon$ is composed of a season-specific error term, $\alpha_{s}$, and everything else that may affect fluctuations in temperature that varies by time period ($t$) and the season, which aren't possible to explicitly include in the model. Hence, $\epsilon_{st} = \alpha_{s} + \eta_{st}$. Let $s$ denote the season and $t$ denote time. For our data set-specific purposes, we will seek to understand how $\text{Temperature}_{st}$ changes with respect to each season and hour ($t$).

Hence, with highly dependent time series data, we will resort to using a $k$th-differences regression model to model the short-run fluctuation in temperature where $k = 5$. In other words, we are going to try to see how temperature changes every five hours and see which factors affect those changes the most.

Hence, for our basic multivariate regression model (w/o interaction terms), if 

$\text{Temperature}_{st} = \beta_0 + \beta_1\text{Humidity}_{st} + \beta_2\text{DewPointTemp}_{st} + \beta_3\text{WindSpeed}_{st} + \beta_4\text{SolarRadiation}_{st} + \beta_5\text{Rainfall}_{st} + \beta_6\text{Snowfall}_{st} + \beta_7I(\text{Hour}_t = 1) + ... + \beta_{29}I(\text{Hour}_t = 23) + \alpha_{s} + \eta_{st}$

Then,

$\text{Temperature}_{st-5} = \beta_0 + \beta_1\text{Humidity}_{st-5} + \beta_2\text{DewPointTemp}_{st-5} + \beta_3\text{WindSpeed}_{st-5} + \beta_4\text{SolarRadiation}_{st-5} + \beta_5\text{Rainfall}_{st-5} + \beta_6\text{Snowfall}_{st-5} + \beta_7I(\text{Hour}_{t-5} = 1) + ... + \beta_{29}I(\text{Hour}_{t-5} = 23) + \alpha_{s} + \eta_{st-5}$

Thus, we wish to estimate,

(1) $\Delta\text{Temperature}_{st} = \beta_1\Delta\text{Humidity}_{st} + \beta_2\Delta\text{DewPointTemp}_{st} + \beta_3\Delta\text{WindSpeed}_{st} + \beta_4\Delta\text{SolarRadiation}_{st} + \beta_5\Delta\text{Rainfall}_{st} + \beta_6\Delta\text{Snowfall}_{st} + \Delta\beta_7I(\text{Hour}_{t} = 1) + ... + \Delta\beta_{29}I(\text{Hour}_{t} = 23) + \Delta\eta_{st}$

#### A.1.0 {#a10}

Regression output and diagnostics for Model (1)

```{r}
seoul.lm = lm(TemperatureChange ~ 0 + ., data=seoul.temp[unique(seoul.change)])
summary(seoul.lm)

autoplot(seoul.lm)
show_leverage(seoul.lm)
```

#### A.1.1 {#a11}

Added Variable Plots for Model (1). After considering the influential points, we determined that the linearity assumption was met.

```{r}
avPlots(seoul.lm)
```

#### A.2.0 {#a20}

Elastic Net Regression on Model (1) w/ interaction terms

```{r eval=F}
model.factors = setdiff(c(seoul.change, seoul.interaction), 
                        c(seoul.base, "TemperatureChange"))

seoul.x = as.matrix(seoul.temp[model.factors])
seoul.y = as.matrix(seoul.temp["TemperatureChange"])

elastic_cv <- cv.glmnet(x = seoul.x,
                      y = seoul.y, 
                      type.measure = "mse", 
                      alpha = 0.5)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.factors)-1)]
elastic.factors = c(model.factors[which(d != 0)])
elastic.factors = c(elastic.factors, setdiff(c(str_c(time.bike, "Change"), "RainfallChange"), elastic.factors))
seoul.elastic = lm(TemperatureChange ~ 0 + .,
                                       seoul.temp[c("TemperatureChange",
                                       elastic.factors)])
```

```{r}
summary(seoul.elastic)
```

#### A.2.1 {#a21}

Model diagnostics for elastic net regression on Model (1) w/ interaction terms

Model assumptions did not drastically improve. QQ-plot indicates that normality assumption is still violated, and is confirmed by a Shapiro-Wilk normality test.

```{r}
autoplot(seoul.elastic)
shapiro.test(sample(seoul.elastic$residuals, 5000))

show_leverage(seoul.elastic)
```

#### A.3 {#a3}

Transformations we considered for Model (1)

```{r fig.size=8}
factors.transform = c("HumidityChange", "DewPointTempChange", 
                      "SolarRadiationChange", "WindSpeedChange")

t = seoul.temp %>% mutate(
  HumidityChange = HumidityChange + abs(min(HumidityChange)) + 1,
  DewPointTempChange = DewPointTempChange + abs(min(DewPointTempChange)) + 1,
  SolarRadiationChange = SolarRadiationChange + abs(min(SolarRadiationChange)) + 1,
  WindSpeedChange = WindSpeedChange + abs(min(WindSpeedChange)) + 1
)

for(i in 1:length(factors.transform)){
  factor = factors.transform[i]
  invTranPlot(formula(str_c("TemperatureChange ~ ", factor)), data=t, 
            lambda = c(-1, -0.5, 0, 0.5, 1, 2), optimal=T)
}
```

#### A.4 {#a4}

An alternative solution to meeting the assumptions for Model (1). In theory,

$\text{Var}(\eta_{st}|s) = \sigma^2 \quad \forall s \in \text{Seasons}$

However, if it's the case that

$\exists \text{ at least one } s \text{ s.t. } \text{Var}(\eta_{st}|s) \neq \sigma^2$

Then, we could use 4 separate models for each season to completely eliminate $s$ out of the general $\eta_{st}$. Hence, each season will have its own population variance for $\eta_t$.

```{r}
create_season_models = function(factors, response, base=F){
  factors = setdiff(factors, response)
  if(base == T){
    f = 0
  } else {
    f = paste(c(0, factors), collapse = " + ")
  }

  models <- map(unique(seoul$Seasons), function(x){
    lm(formula(paste(response, "~", f)),
       data = seoul[seoul$Seasons == x,] %>%
         select(all_of(c(factors, response))))
  })

  names(models) <- str_c("seoul.lm.", unique(seoul$Seasons))
  return(models)
}

models.lm = create_season_models(seoul.change, "TemperatureChange")

create_elastic = function(){
  models = list()
  seasons = seoul$Seasons %>% unique()
  for(s in seasons){
    #print(s)
    seoul.subset = seoul.temp %>% filter(Seasons == s)
    seoul.x = as.matrix(seoul.subset[model.factors])
    seoul.y = as.matrix(seoul.subset["TemperatureChange"])

    elastic_cv <- cv.glmnet(x = seoul.x,
                          y = seoul.y,
                          type.measure = "mse",
                          alpha = 0.5)

    d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.factors)-1)]
    elastic.factors = model.factors[which(d != 0)]
    models[[str_c("seoul.lasso.",s)]] = lm(TemperatureChange ~ 0 + .,
                                           seoul.subset[c("TemperatureChange",
                                           elastic.factors)])
  }
  return(models)
}
seoul.elastic.models = create_elastic()
for(model in seoul.elastic.models){
  print(summary(model))
  print(autoplot(model))
}
```

#### A.5 {#a5}

Most assailant factors in Model (2) (hour changes excluded)

```{r}
elastic.coef = tibble(
  Factor = names(seoul.elastic$coefficients),
  Coefficient = seoul.elastic$coefficients,
  P.Value = summary(seoul.elastic)$coefficients[,"Pr(>|t|)"] %>% round(5) %>%
    format(scientific=F)
) %>% arrange(abs(Coefficient) %>% desc())

elastic.coef$Rank = 1:nrow(elastic.coef)

elastic.coef %>% 
  filter(!(Factor %in% str_c(time.bike, "Change"))) %>%
  knitr::kable()
```

#### A.6 {#a6}

The theoretical model for Model (2) can be fully written as,

(2) $\Delta\text{Temperature}_{st} = \beta_1\Delta\text{Humidity}_{st} + \beta_2\Delta\text{DewPointTemp}_{st} + \beta_3\Delta\text{Visibility}_{st} + \beta_4\Delta\text{WindSpeed}_{st} + \beta_5\Delta\text{SolarRadiation}_{st} + \beta_6\Delta\text{Rainfall}_{st} + \beta_7\Delta\text{Snowfall}_{st} + \beta_8\Delta I(\text{Hour}_{t} = 1) + ... + \beta_{30}\Delta I(\text{Hour}_{t} = 23) + \beta_{31}\Delta\text{Humidity}_{st}\text{DewPointTemp}_{st} + \beta_{32}\Delta\text{Humidity}_{st}\text{SolarRadiation}_{st}+\beta_{33}\Delta\text{Humidity}_{st}\text{Rainfall}_{st} + \beta_{34}\Delta\text{Humidity}_{st}\text{Snowfall}_{st} + \beta_{35}\Delta\text{DewPointTemp}_{st}\text{WindSpeed}_{st} + \beta_{36}\Delta\text{DewPointTemp}_{st}\text{Rainfall}_{st} + \beta_{37}\Delta\text{WindSpeed}_{st}\text{Visibility}_{st}+\beta_{38}\Delta\text{WindSpeed}_{st}\text{solarRadiation}_{st} + \beta_{39}\Delta\text{SolarRadiation}_{st}\text{Rainfall}_{st}+ \\ \sum_{j=1}^{23}{\beta_{39+j}\Delta\text{Humidity}_{st}\Delta I(\text{Hour}_t=j)}+\sum_{k=1}^{23}{\beta_{62+k}\Delta\text{DewPointTemp}_{st}\Delta I(\text{Hour}_t=k)}+\sum_{l=1}^{23}{\beta_{85+l}\Delta\text{WindSpeed}_{st}\Delta I(\text{Hour}_t=l)}+\sum_{m=1}^{23}{\beta_{108+m}\Delta\text{Visibility}_{st}\Delta I(\text{Hour}_t=m)}+\sum_{n=1}^{23}{\beta_{131+n}\Delta\text{SolarRadiation}_{st}\Delta I(\text{Hour}_t=n)}+\sum_{o=1}^{23}{\beta_{154+o}\Delta\text{Rainfall}_{st}\Delta I(\text{Hour}_t=o)}+\sum_{p=1}^{23}{\beta_{177+p}\Delta\text{Snowfall}_{st}\Delta I(\text{Hour}_t=p)} + \Delta\eta_{st}$

$\Delta\eta_{st} \overset{iid}{\sim} N(0, \sigma^2)$

Due to the nature of elastic net regression, some of the coefficients for $j, k, l, m, n, o,$ and $p$ are $0$:

$\beta_{39+j} = 0 \quad \forall j \in \{3,13,15,18,20\}$

$\beta_{62+k} = 0 \quad \forall k \in \{3,5,6,7,8,12,15,22,23\}$

$\beta_{85+l} = 0 \quad \forall l \in \{1,2,3,7,8,9,12,13,14,16,20,21,22,23\}$

$\beta_{108+m} = 0 \quad \forall m \in \{5,6,7,,10,12,13,14,15,18,21,22\}$

$\beta_{131+n} = 0 \quad \forall n \in \{8,9,15,16,18,21,22\}$

$\beta_{154+o} = 0 \quad \forall o \in \{1,...,8,11,12,13,15,16,17,18,19,23\}$

$\beta_{177+p} = 0 \quad \forall p \in \{1,...,7,11,...,15,17,18,20,21,22,23\}$

#### A.7 {#a7}

Choosing the optimal set of lagged effects, $\delta_p \quad \forall p \in P$

Similar to choosing $k$ in our $k$th-difference model such that $\Delta\text{Temperature}_{st}$ was no longer dependent on $\Delta\text{Temperature}_{st-k}$, we need to find the optimal set $P$ such that $\text{RentedBikeCount}_{st}$ is no longer dependent on $\text{RentedBikeCount}_{st-p} \quad \forall p \in P$. To do this, we need to find the maximum lags ($max(P)$) that makes it so there is no longer a significant marginal effect on $\text{RentedBikeCount}_{st}$.

```{r}

find_local_max = function(v){
  if(v[2] <= v[1]){
    maxes = v[1]
  } else {
    maxes = c()
  }
  
  for(i in 1:length(v)){
    if(i-1 >= 1 && i+1 <= length(v)){
      if(v[i-1] <= v[i] && 
         v[i+1] <= v[i]){
        maxes = c(maxes, v[i])
      }
    }
  }
  
  if(v[length(v)] >= v[(length(v)-1)]){
    maxes = c(maxes, v[length(v)])
  }
  
  return(maxes)
}

graphs = list()

for(season in seoul$Seasons %>% unique()){
  l = 1
  alpha = 0.05
  seoul.subset = seoul %>% filter(Seasons == season)
  deltas = cov(seoul.subset$RentedBikeCount[(l+1):length(seoul.subset$RentedBikeCount)], 
      lag(seoul.subset$RentedBikeCount, n=l)[(l+1):length(seoul.subset$RentedBikeCount)])/
  var(seoul.subset$RentedBikeCount[(l+1):length(seoul.subset$RentedBikeCount)])
  p.value = 0
  
  while(p.value < alpha){
    l = l+1
    
    deltas = c(deltas, cov(seoul.subset$RentedBikeCount[(l+1):length(seoul.subset$RentedBikeCount)], 
      lag(seoul.subset$RentedBikeCount, n=l)[(l+1):length(seoul.subset$RentedBikeCount)])/
    var(seoul.subset$RentedBikeCount[(l+1):length(seoul.subset$RentedBikeCount)]))
    
    l.lm = lm(seoul.subset$RentedBikeCount[(l+1):length(seoul.subset$RentedBikeCount)] ~ 
         lag(seoul.subset$RentedBikeCount, n=l)[(l+1):length(seoul.subset$RentedBikeCount)]) %>%
      summary()
    p.value = l.lm$coefficients[, "Pr(>|t|)"][2]
  }
  
  local.max = find_local_max(deltas)
  deltas.max = which(deltas %in% local.max)
  
  p = ggplot(mapping=aes(x=1:l, y=deltas))+
    geom_point()+
    geom_line()+
    xlab("Lags (Hours Ago)")+
    ylab(expression(delta[p]))+
    scale_x_continuous(breaks=1:l)+
    labs(title=str_c("Pth Lagged Effects on Rented Bike Count During ", season))
  
  print(p)
}
```

Since Spring is our base season, we will include $p=9$ lagged effects for $\text{RentedBikeCount}_{st}$ in the base model, and since no other season has $p > 9$, we do not need any other lagged effects dependent on season.

#### A.8.0 {#a80}

Model 3 can be fully written as,

(3) $\text{RentedBikeCount}_{st} = \beta_0 + \beta_1\text{Humidity}_{st} + \beta_{2}\text{Temperature}_{st} + \beta_{3}\text{WindSpeed}_{st} + \beta_{4}\text{Visibility}_{st} + \beta_{5}\text{DewPointTemp}_{st} + \beta_{6}\text{SolarRadiation}_{st} + \beta_{7}\text{Rainfall}_{st} + \beta_{8}\text{Snowfall}_{st} + \beta_{9}I(\text{Day}_t = Holiday) + \beta_{10}I(\text{Hour}_t = 1) + ... + \beta_{32}I(\text{Hour}_t = 23) + \beta_{33}I(\text{Season}_s = \text{Winter}) + \beta_{34}I(\text{Season}_s = \text{Summer}) + \beta_{35}I(\text{Season}_s = \text{Autumn}) + \delta_1\text{RentedBikeCount}_{st-1} + \delta_{23}\text{RentedBikeCount}_{st-23} + \sum_{p=1}^{9}\delta_p + \eta_{st}$

#### A.8 {#a8}

Fitting a linear model to estimate parameters for Model (3)

```{r}
model.3.factors = c(seoul.bike.factors, 
                                bike.deltas)%>% setdiff(c(
                                time.humidities, seoul.bike.transformed))

seoul.bike.lm = lm(RentedBikeCount ~ ., 
                   data=seoul[model.3.factors])
summary(seoul.bike.lm)
autoplot(seoul.bike.lm)
show_leverage(seoul.bike.lm)
```

Linearity seems to be roughly met and even Normality can be appealed to. However, in the $\sqrt{|\text{Standardized residuals}|)}$ vs. Fitted values Plot, homoskedasticity appears to be violated, with some interesting trends happening with fitted values < 1000.

#### A.9 {#a9}

Including all necessary interaction terms, we ran an elastic net regression to see if we could better meet the model assumptions.

```{r}
singularities = c("SolarRadiationXHour1", "SolarRadiationXHour2", "SolarRadiationXHour3",
                  "SnowfallXIsFunctioningDay", "SolarRadiationXHour4",
                  "SolarRadiationXHour5", "SolarRadiationXHour20", "SolarRadiationXHour21",
                  "SolarRadiationXHour22", "SolarRadiationXHour23", "SnowfallXIsSummer",
                  "SnowfallXIsAutumn")

seoul = create_interaction_terms(seoul)

model.bike.factors = setdiff(c(seoul.bike.factors, seoul.bike.interaction), 
                             c(seoul.bike.base, "RentedBikeCount", singularities,
                               humidity.interactions))

seoul.bike.x = as.matrix(seoul[(length(bike.deltas)+1):nrow(seoul),model.bike.factors])
seoul.bike.y = as.matrix(seoul[(length(bike.deltas)+1):nrow(seoul),"RentedBikeCount"])

elastic_cv <- cv.glmnet(x = seoul.bike.x,
                      y = seoul.bike.y, 
                      type.measure = "mse", 
                      alpha = 1)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.bike.factors)-1)]
elastic.bike.factors = model.bike.factors[which(d != 0)]
seoul.bike.elastic = lm(RentedBikeCount ~ .,
                                       seoul[c("RentedBikeCount",
                                       elastic.bike.factors)])

print(summary(seoul.bike.elastic))
autoplot(seoul.bike.elastic)
show_leverage(seoul.bike.elastic)
```

#### A.10.0 {#a100}

Transformations of Model (3)

We first considered a log transformation of $\text{RentedBikeCount}_{st}$

```{r}
seoul$RentedBikeCount = log(seoul$RentedBikeCount + 1)
calculate_deltas()
seoul = create_interaction_terms(seoul)

seoul.bike.x = as.matrix(seoul[(length(bike.deltas)+1):nrow(seoul),model.bike.factors])
seoul.bike.y = as.matrix(seoul[(length(bike.deltas)+1):nrow(seoul),"RentedBikeCount"])

elastic_cv <- cv.glmnet(x = seoul.bike.x,
                      y = seoul.bike.y, 
                      type.measure = "mse", 
                      alpha = 1)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.bike.factors)-1)]
elastic.bike.factors.log = model.bike.factors[which(d != 0)]
seoul.bike.elastic.log = lm(RentedBikeCount ~ .,
                                       seoul[c("RentedBikeCount",
                                       elastic.bike.factors.log)])

print(summary(seoul.bike.elastic.log))
autoplot(seoul.bike.elastic.log)
show_leverage(seoul.bike.elastic.log)
```

Strange trends happen in homoskedasticity when fitted values approach zero, which may be exacerbating the strange trends seen in the Residuals vs. Fitted values plot. Overall, the model assumptions did not approve with a log transformation.

```{r echo=F}
#Change it back
seoul$RentedBikeCount = exp(seoul$RentedBikeCount)-1
calculate_deltas()
seoul = create_interaction_terms(seoul)
```

#### A.10.1 {#a101}

Non-linearity in the Humidity vs. # of Rented Bikes

```{r message=F}
seoul %>% ggplot(aes(x=Humidity, y=RentedBikeCount))+
  geom_point()+
  geom_smooth(method="lm", se=F)+
  facet_grid(~Seasons)

t = seoul %>%
  mutate(
    Humidity = Humidity + 1,
    Visibility = Visibility + 1,
    WindSpeed = WindSpeed + 1,
  )

invTranPlot(RentedBikeCount ~ Humidity, data=t, 
            lambda = c(-1, -0.5, 0, 0.5, 1), optimal=T)
```

Due to the non-linearity in $\text{Humidity}_{st}$, and the impracticality of transforming it (a $\lambda = 6$ is not ideally interpretable), we decided to include 9 (ommitting a first level to preserve the full rank of $X'X$) levels of humidity as dummy variables to isolate non-linear effects.

Hence, we included $\sum_{i=1}^{9}\beta_iI(10i \leq Humidity_{st} < 10(i+1))$ as categorical variables.

#### A.10.2 {#a102}

An ideal transformation for $\text{Visibility}_{st}$

```{r}
invTranPlot(RentedBikeCount ~ Visibility, data=t, 
            lambda = c(-1, -0.5, 0, 0.5, 1), optimal=T)
```

Based on the Inverse Response Plot, the best transformation for $\text{Visibility}_{st}$ for interpretable results is a $log$ transformation ($\lambda=0$).

#### A.10.3 {#a103}

Transforming $\text{WindSpeed}_{st}$

```{r}
invTranPlot(RentedBikeCount ~ WindSpeed, data=t, 
            lambda = c(-1, -0.5, 0, 0.5, 1), optimal=T)
```

An ideal transformation for $\text{WindSpeed}_{st}$ could be an inverse transformation. However, upon further analysis of the sample distribution of $\text{WindSpeed}_{st}$, there are extreme values of wind that may be skewing the results:

```{r}
hist(seoul$WindSpeed, main="Histogram of Wind Speed (m/s)",
     xlab="Wind Speed (m/s)")
```

Hence, filtering out extreme values of wind,

```{r}
t %>% filter(WindSpeed < quantile(WindSpeed, 0.9)) -> t

invTranPlot(RentedBikeCount ~ WindSpeed, data=t, 
            lambda = c(-1, -0.5, 0, 0.5, 1), optimal=T)
```

We will apply two transformations as follows:

(1) Define a new categorical variable called $\text{ExtremeWind}_{st}$ that will be either 1 or 0 depending if $\text{WindSpeed}_{st} \geq \phi(0.9|\text{Season}=s)$, where $\phi$ is the inverse CDF of $F(\text{WindSpeed}_{st} \leq c)$
(2) Transform $\text{WindSpeed}_{st}$ such that values that classify as $\text{ExtremeWind}_{st}$ are 0, and all other values follow a $log$ transformation as denoted by the inverse response plot.

This isolates the linear trend in the "non-extreme" wind-speeds, and gives the extreme wind categorical variable it's own marginal effect that we can distinguish.

#### A.11 {#a11}

Elastic net regression and output on Model (4)

```{r}
elastic_cv <- cv.glmnet(x = seoul.bike.x,
                      y = seoul.bike.y, 
                      type.measure = "mse", 
                      alpha = 1)

d = coef(elastic_cv, s = "lambda.1se")[2:(length(model.bike.factors)-1)]


elastic.bike.factors = c(model.bike.factors[which(d != 0)])

#Add lower level terms
elastic.bike.factors = c(elastic.bike.factors, 
                         setdiff(seoul.bike.factors.alt,
                        c("RentedBikeCount", elastic.bike.factors)))

seoul.bike.elastic = lm(RentedBikeCount ~ .,
                                       seoul.bike[c("RentedBikeCount",
                                       elastic.bike.factors)])

print(summary(seoul.bike.elastic))
autoplot(seoul.bike.elastic)
show_leverage(seoul.bike.elastic)
```

#### A.12

Most Assailant Factors for Model (4), w/ lagged effects (and lagged interactions) and lower level time effects removed

```{r}
elastic.bike.coef = tibble(
  Factor = names(seoul.bike.elastic$coefficients),
  Coefficient = seoul.bike.elastic$coefficients,
  P.Value = summary(seoul.bike.elastic)$coefficients[,"Pr(>|t|)"] %>% round(5) %>%
    format(scientific=F)
) %>% arrange(abs(Coefficient) %>% desc())

elastic.bike.coef$Rank = 1:nrow(elastic.bike.coef)

elastic.bike.coef %>% 
  filter(!(str_detect(Factor, "RentedBikeCount") | 
           Factor %in% time.bike)) %>%
  knitr::kable()
```

#### A.13 {#a13}

The full model (Model 4), can be written as, 

$\text{RentedBikeCount}_{st} = \beta_0 + \sum_{i=1}^{9}\beta_iI(10i\leq\text{Humidity}_{st}< 10(i+1))+\beta_{10}ln(\text{Visibility}_{st}+1) + \beta_{11}\text{Rainfall}_{st} +\beta_{12}\text{Temperature}_{st}+\beta_{13}(ln\text{WindSpeed}_{st}+1)+\beta_{14}I(\text{ExtremeWind}_{st}=1)+\beta_{15}\text{DewPointTemp}_{st}+\beta_{16}\text{Snowfall}_{st}+\beta_{17}\text{SolarRadiation}_{st}+\\\beta_{18}I(\text{Day}_t=\text{Holiday}_{t})+\beta_{19}I(\text{Season}_s = \text{Winter}) + \beta_{20}I(\text{Season}_s = \text{Summer}) + \beta_{21}I(\text{Season}_s = \text{Autumn}) + \sum_{i=1}^{23}\beta_{21+i}I(\text{Hour}_t=i) + \sum_{h=1}^{9}\sum_{i=1}^{23}\beta_{44+ih}I(\text{Hour}_t=i)I(10h\leq\text{Humidity}_{st}< 10(h+1)) + \sum_{i=1}^9\beta_{207+i}I(\text{Hour}_t=i)I(\text{Day}_t=\text{Holiday}) + \\\beta_{217}\text{Temperature}_{st}\text{DewPointTemp}_{st} + \beta_{218}ln(\text{WindSpeed}_{st}+1)I(\text{Day}_t=\text{Holiday}_{st}) + \beta_{218}\text{SolarRadiation}_{st}\text{Rainfall}_{st} + \beta_{219}\text{SolarRadiation}_{st}I(\text{Day}_t=\text{Holiday}_{st}) + \beta_{220}\text{Snowfall}_{st}I(\text{ExtremeWind}_{st} = 1)+\\\beta_{221}\text{Temperature}_{st}I(\text{Hour}_t=1)+\beta_{222}\text{Temperature}_{st}I(\text{Hour}_t=7)+\beta_{223}\text{Temperature}_{st}I(\text{Hour}_t=18)+\beta_{224}ln(\text{WindSpeed}_{st}+1)I(\text{Hour}_t=1)+\beta_{225}ln(\text{WindSpeed}_{st}+1)I(\text{Hour}_t=3)+\beta_{226}ln(\text{WindSpeed}_{st}+1)I(\text{Hour}_t=11)+\\\beta_{227}ln(\text{WindSpeed}_{st}+1)I(\text{Hour}_t=18) \beta_{228}ln(\text{Visibility}_{st}+1)I(\text{Hour}_t=2)+...+\beta_{230}ln(\text{Visibility}_{st}+1)I(\text{Hour}_t=4)+\beta_{231}ln(\text{Visbility}_{st}+1)I(\text{Hour}_t=11)+\beta_{232}\text{DewPointTemp}_{st}I(\text{Hour}_t=5)+\beta_{233}\text{DewPointTemp}_{st}I(\text{Hour}_t=8)+\\\beta_{234}\text{DewPointTemp}_{st}I(\text{Hour}_t=11)+\beta_{235}\text{DewPointTemp}_{st}I(\text{Hour}_t=16)+\beta_{236}\text{DewPointTemp}_{st}I(\text{Hour}_t=17)+\beta_{237}\text{DewPointTemp}_{st}I(\text{Hour}_t=19)+...+\beta_{239}\text{DewPointTemp}_{st}I(\text{Hour}_t=21)+\beta_{240}\text{SolarRadiation}_{st}I(\text{Hour}_t=8)+\\\beta_{241}\text{SolarRadiation}_{st}I(\text{Hour}_t=19)+\beta_{242}\text{Rainfall}_{st}I(\text{Hour}_t=9)+\beta_{243}\text{Rainfall}_{st}I(\text{Hour}_t=13)+\beta_{244}\text{Rainfall}_{st}I(\text{Hour}_t=17)+\beta_{245}\text{Rainfall}_{st}I(\text{Hour}_t=19)+\beta_{246}\text{Rainfall}_{st}I(\text{Hour}_t=20)+\beta_{247}\text{Snowfall}_{st}I(\text{Hour}_t=7)+\beta_{248}\text{Snowfall}_{st}I(\text{Hour}_t=9)+\beta_{249}\text{Snowfall}_{st}I(\text{Hour}_t=13)+\\\beta_{250}I(\text{ExtremeWind}_{st}=1)I(\text{Hour}_t=8)+\beta_{251}I(\text{ExtremeWind}_{st}=1)I(\text{Hour}_t=18)+\beta_{252}I(\text{ExtremeWind}_{st}=1)I(\text{Hour}_t=19)+\beta_{253}ln(\text{WindSpeed}_{st}+1)I(\text{Season}_s=\text{Winter})+\beta_{254}ln(\text{Visibility}_{st}+1)I(\text{Season}_s=\text{Winter})+\beta_{255}\text{SolarRadiation}_{st}I(\text{Season}_s=\text{Summer})+\\\beta_{256}\text{SolarRadiation}_{st}I(\text{Season}_s=\text{Autumn})+\beta_{257}\text{Rainfall}_{st}I(\text{Season}_s=\text{Winter})+\sum_{i=1}^{23}\sum_{\text{All } j \in \text{Seasons, }j\neq\text{Spring}}\beta_{257+i*jth\text{ Season}}I(\text{Hour}_t=i)I(\text{Season}_s=j)+\sum_{i=i}^{3}\beta_{327+i}I(60+10i\leq\text{Humidity}_{st}<60+10(i+1))I(\text{Season}_s=\text{Autumn})+\\\beta_{331}I(60\leq\text{Humidity}_{st}<70)I(\text{Season}_s=\text{Summer})+\beta_{332}\text{Temperature}_{st}I(20\leq\text{Humidity}_{st}<30)+\beta_{333}ln(\text{WindSpeed}_{st}+1)I(90\leq\text{Humidity}_{st}<100)+\beta_{334}\text{SolarRadiation}_{st}I(60\leq\text{Humidity}_{st}<70)+\sum_{i=1}^{4}\beta_{335+i}\text{SolarRadiation}_{st}I(50+10i\leq\text{Humidity}_{st}<60+10(i+1))+\\\sum_{i=1}^{3}\beta_{339+i}\text{Rainfall}_{st}I(30+10i\leq\text{Humidity}_{st}<30+10(i+1))+\beta_{343}\text{Rainfall}_{st}I(90\leq\text{Humidity}_{st}<100)+\beta_{344}I(\text{ExtremeWind}_{st}=1)I(30\leq\text{Humidity}_{st}<40)+\beta_{345}I(\text{ExtremeWind}_{st}=1)I(60\leq\text{Humidity}_{st}<70)+\beta_{346}I(\text{ExtremeWind}_{st}=1)I(70\leq\text{Humidity}_{st}<80)+\\\sum_{p=1}^{9}\delta_p\text{RentedBikeCount}_{st-p} + \sum_{p=1}^{9}\sum_{t=1}^{23}\delta_{9+pt}\text{RentedBikeCount}_{st-p}I(\text{Hour}_t=t) +  \sum_{p=1}^{9}\sum_{i=1}^{9}\delta_{216+ip}\text{RentedBikeCount}_{st-p}I(10i < \text{Humidity}_{st} \leq10(i+1)) +\\ \delta_{298}\text{RentedBikeCount}_{st-1}I(\text{Season}_s=\text{Autumn})+\delta_{299}\text{RentedBikeCount}_{st-3}I(\text{Season}_s=\text{Summer})+\delta_{300}\text{RentedBikeCount}_{st-6}I(\text{Season}_s=\text{Summer})+\delta_{301}\text{RentedBikeCount}_{st-9}I(\text{Season}_s=\text{Autumn})+\\\delta_{302}\text{RentedBikeCount}_{st-2}\text{RentedBikeCount}_{st-5}+\delta_{303}\text{RentedBikeCount}_{st-2}\text{RentedBikeCount}_{st-6}+\delta_{304}\text{RentedBikeCount}_{st-5}I(\text{ExtremeWind}_{st} = 1) + \delta_{305}\text{RentedBikeCount}_{st-1}\text{Temperature}_{st} + \\\delta_{306}\text{RentedBikeCount}_{st-1}ln(\text{WindSpeed}_{st}+1)+\delta_{307}\text{RentedBikeCount}_{st-9}ln(\text{WindSpeed}_{st}+1)+\delta_{308}\text{RentedBikeCount}_{st-1}ln(\text{Visibility}_{st}+1)+\delta_{309}\text{RentedBikeCount}_{st-1}\text{SolarRadiation}_{st}+\delta_{310}\text{RentedBikeCount}_{st-9}\text{SolarRadiation}_{st}+\\\delta_{311}\text{RentedBikeCount}_{st-1}\text{Rainfall}_{st}+\delta_{312}\text{RentedBikeCount}_{st-3}\text{Rainfall}_{st}+\delta_{313}\text{RentedBikeCount}_{st-8}\text{Rainfall}_{st}+\delta_{314}\text{RentedBikeCount}_{st-9}\text{Snowfall}_{st}+\eta_{st}$

$\eta_{st} \overset{iid}{\sim} N(0, \sigma^2)$

NOTE: Not all paramenter coefficients are estimated to be > 0. See model output to see which coefficients.

#### A.14 {#a14}

Model Output for Model 4

```{r}
summary(seoul.bike.elastic)
```

#### A.15 {#a15}

```{r echo=F}
api_url <- "https://api.open-meteo.com/v1/forecast?latitude=37.566&longitude=126.9784&hourly=temperature_2m,relative_humidity_2m,dew_point_2m,rain,snowfall,visibility,wind_speed_10m,diffuse_radiation&wind_speed_unit=ms&past_days=7"
```

```{r warning=F, fig.width=18}
response <- GET(api_url)
fetch_time = ymd_h(paste(Sys.Date(), hour(now())))
content <- content(response, "text", encoding = "UTF-8")

data <- fromJSON(content)

hourly_data <- data$hourly

forecast <- as_tibble(hourly_data) %>% mutate(
  time = as.POSIXct(time, format = "%Y-%m-%dT%H:%M"),
  diffuse_radiation = diffuse_radiation/100,
  visibility = visibility/100,
  Hour = time %>% hour(),
  f = time >= as.POSIXct(fetch_time, format = "%Y-%m-%dT%H:%M")
) %>% setNames(c("Time", "Temperature", "Humidity", "DewPointTemp", "Rainfall", "Snowfall",
               "Visibility", "WindSpeed", "SolarRadiation", "Hour", "Forecast"))

forecast$Seasons = "Winter"

time.forecast = c()
for(h in unique(forecast$Hour)){
  factor = str_c("Hour", h)
  forecast[factor] = as.numeric(forecast$Hour == h)
  time.forecast = c(time.forecast, factor)
}
time.forecast.base = "Hour0"
time.forecast = setdiff(time.forecast, time.forecast.base)

forecast.factors = c("Temperature", "Humidity", "DewPointTemp",
                  "WindSpeed", "Visibility", "SolarRadiation", "Rainfall",
                  "Snowfall", time.forecast)

forecast = format_change_table(forecast)

forecast$PredictedChange = predict(seoul.elastic, forecast)
forecast$PredictedTemperature = forecast$PredictedChange+
  lag(forecast$Temperature, n=difference)

forecast[complete.cases(forecast[forecast.factors]),] -> forecast

pred_ints <- predict(seoul.elastic,
        newdata = forecast,
        interval = "prediction",
        level = 0.95)

forecast$LowerBoundTemperatureChange = pred_ints[, "lwr"]
forecast$UpperBoundTemperatureChange = pred_ints[, "upr"]

forecast$LowerBoundTemperature = forecast$LowerBoundTemperatureChange +
  lag(forecast$Temperature, n=difference)
forecast$UpperBoundTemperature = forecast$UpperBoundTemperatureChange +
  lag(forecast$Temperature, n=difference)

p.change = forecast %>% ggplot(aes(x=Time, y=TemperatureChange, color=Forecast))+
  geom_line() +
  geom_ribbon(aes(ymin=LowerBoundTemperatureChange, ymax=UpperBoundTemperatureChange), 
              color=NA, fill="#14DD32", alpha=0.2) +
  geom_line(aes(y=PredictedChange), color="#14DD32", alpha=0.5)+
  ylab(expression(Delta~Temperature))+
  labs(
    title="Current Weekly Forecast of Change in Temperature in Seoul",
    subtitle = "Overlaid by Prediction"
  )+
  guides(color="none")+
  theme_minimal()

p.temp = forecast %>% ggplot(aes(x=Time, y=Temperature, color=Forecast))+
  geom_line() +
  geom_ribbon(aes(ymin=LowerBoundTemperature, ymax=UpperBoundTemperature),
              color=NA, fill="#14DD32", alpha=0.2) +
  geom_line(aes(y=PredictedTemperature), color="#14DD32", alpha=0.5)+
  ylab("Temperature")+
  labs(
    title="Current Weekly Forecast of Temperature in Seoul",
    subtitle = "Overlaid by Prediction"
  )+
  theme_minimal()

grid.arrange(p.change, p.temp, ncol=2)
```